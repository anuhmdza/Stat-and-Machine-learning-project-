---
title: "bsts-ml"
author: "Emily Ortega"
date: 
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(bsts)
library(dplyr)

# Load data
df <-  read.csv("C:/Users/emily/Downloads/final_model_dataset_with_features.csv")

# Columns to exclude from predictors
exclude_cols <- c("state", "year", "cases")

# Store models
state_models <- list()

# Loop through each state
for (state in unique(df$state)) {
  state_data <- df %>% filter(state == !!state) %>% arrange(year)
  
  y <- state_data$cases
  predictors <- state_data %>% select(-all_of(exclude_cols))
  
  # Compute sd safely
  y_sd <- sd(y, na.rm = TRUE)
  
  # Fit model only if y has at least 2 non-missing values and sd > 0
  if (sum(!is.na(y)) >= 2 && !is.na(y_sd) && y_sd > 0) {
    ss <- AddLocalLinearTrend(list(), y)
    model <- bsts(y ~ ., state.specification = ss, data = predictors, niter = 1000)
    state_models[[state]] <- model
    cat("✓ Finished modeling for state:", state, "\n")
  } else {
    cat("Skipping", state, "- insufficient data or no variation in cases.\n")
  }
}

```

```{r}
library(Metrics)  # for mae and rmse

for (state in names(state_models)) {
  model <- state_models[[state]]
  
  # Get in-sample predicted values (posterior mean)
  pred <- colMeans(model$one.step.prediction.errors, na.rm = TRUE)
  actual <- model$original.series

  # Remove any NA (can happen if model skips prediction for early points)
  valid_idx <- which(!is.na(actual) & !is.na(pred))
  
  if (length(valid_idx) >= 2) {
    actual <- actual[valid_idx]
    pred <- pred[valid_idx]
    
    state_mae <- mae(actual, actual - pred)
    state_rmse <- rmse(actual, actual - pred)
    
    cat(sprintf("State: %s | MAE: %.3f | RMSE: %.3f\n", state, state_mae, state_rmse))
  } else {
    cat(sprintf("State: %s has too few valid predictions for metrics.\n", state))
  }
}

```

```{r}
library(Metrics)  # for mae and rmse

# Store results for averaging
mae_list <- c()
rmse_list <- c()

for (state in names(state_models)) {
  model <- state_models[[state]]
  
  # Get in-sample predicted values (posterior mean)
  pred <- colMeans(model$one.step.prediction.errors, na.rm = TRUE)
  actual <- model$original.series

  # Only keep valid predictions
  valid_idx <- which(!is.na(actual) & !is.na(pred))
  
  if (length(valid_idx) >= 2) {
    actual <- actual[valid_idx]
    pred <- actual - pred[valid_idx]  # one-step errors, so y_t = error_t + prediction_t
    
    state_mae <- mae(actual, pred)
    state_rmse <- rmse(actual, pred)
    
    mae_list <- c(mae_list, state_mae)
    rmse_list <- c(rmse_list, state_rmse)
  }
}

# Calculate and print averages
avg_mae <- mean(mae_list)
avg_rmse <- mean(rmse_list)

cat(sprintf("\n Average MAE across models: %.3f", avg_mae))
cat(sprintf("\nAverage RMSE across models: %.3f", avg_rmse))

```

```{r}

library(bsts)
library(ggplot2)
library(dplyr)



# Define full year range for all plots
full_years <- 2016:2022

# Loop through each state
for (state in names(state_models)) {
  model <- state_models[[state]]

  # Step 1: Get one case value per year for the state (first row per year)
  actual_df <- df %>%
    filter(state == state, year %in% full_years) %>%
    arrange(year) %>%
    group_by(year) %>%
    slice(1) %>%
    ungroup() %>%
    select(year, cases)

  # Step 2: Build plot_df with all years and pad with NA where missing
  plot_df <- data.frame(Year = full_years) %>%
    left_join(actual_df, by = c("Year" = "year")) %>%
    rename(Actual = cases)

  # Step 3: Add Predicted column initialized as NA
  plot_df$Predicted <- NA

  # Step 4: Get model errors and calculate predicted values if available
  pred_errors <- tryCatch({
    colMeans(model$one.step.prediction.errors, na.rm = TRUE)
  }, error = function(e) {
    rep(NA, nrow(plot_df))
  })

  # Step 5: Fill predicted values using: predicted = actual - error
  len <- min(nrow(plot_df), length(pred_errors))
  if (len >= 1) {
    plot_df$Predicted[1:len] <- plot_df$Actual[1:len] - pred_errors[1:len]
  }

  # Step 6: Only plot if there’s at least some data to show
  if (sum(!is.na(plot_df$Actual)) >= 2 || sum(!is.na(plot_df$Predicted)) >= 2) {
    print(
      ggplot(plot_df, aes(x = Year)) +
        geom_line(aes(y = Actual, color = "Actual"), size = 1.1, na.rm = TRUE) +
        geom_point(aes(y = Actual, color = "Actual"), size = 2, shape = 16, na.rm = TRUE) +
        geom_line(aes(y = Predicted, color = "Predicted"), size = 1.1, linetype = "dashed", na.rm = TRUE) +
        geom_point(aes(y = Predicted, color = "Predicted"), size = 2, shape = 4, na.rm = TRUE) +
        scale_color_manual(values = c("Actual" = "blue", "Predicted" = "orange")) +
        scale_x_continuous(breaks = full_years, labels = as.character(full_years)) +
        labs(title = paste(state, "- BSTS Predictions vs Actual"),
             x = "Year", y = "Cases", color = "") +
        theme_minimal(base_size = 14) +
        theme(
          panel.grid.major = element_line(color = "gray85"),
          panel.grid.minor = element_blank(),
          legend.position = "top"
        )
    )
  } else {
    cat("Skipping", state, "- not enough data to plot.\n")
  }
}



```